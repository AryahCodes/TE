{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde83efb97fddb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.set_num_threads(30)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Constants\n",
    "# QPINN Parameters\n",
    "N_LAYERS = 5\n",
    "N_WIRES = 4\n",
    "\n",
    "# FNN Basis Net\n",
    "HIDDEN_LAYERS_FNN = 2\n",
    "NEURONS_FNN = 10\n",
    "\n",
    "# Domain Parameter\n",
    "T_COLLOC_POINTS = 50\n",
    "X_COLLOC_POINTS = 100\n",
    "BOUNDARY_SCALE = 10e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a31e7e988822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Collocation Points\n",
    "t = torch.linspace(0.0, 0.95, T_COLLOC_POINTS)\n",
    "x = torch.linspace(-1.0, 1.0, X_COLLOC_POINTS)\n",
    "input_domain = torch.tensor(list(product(t, x)))\n",
    "\n",
    "init_val_mask = input_domain[:, 0] == 0.0\n",
    "init_val_colloc = input_domain[init_val_mask]\n",
    "\n",
    "# Dirichlet Boundary\n",
    "dir_boundary_mask = (input_domain[:, 1] == -1.0) | (input_domain[:, 1] == 1.0)\n",
    "dir_boundary_colloc = input_domain[dir_boundary_mask & ~init_val_mask]\n",
    "\n",
    "# Combined Boundary Mask\n",
    "boundary_mask = init_val_mask | dir_boundary_mask\n",
    "\n",
    "# Filter out boundary points from domain_colloc\n",
    "interior_colloc = input_domain[~boundary_mask]\n",
    "\n",
    "# plt.scatter(init_val_colloc[:,0],init_val_colloc[:,1], c=\"r\")\n",
    "# plt.scatter(periodic_boundary_colloc[:,0],periodic_boundary_colloc[:,1], c=\"blue\")\n",
    "# plt.scatter(interior_colloc[:,0],interior_colloc[:,1], c=\"black\")\n",
    "# plt.show()\n",
    "\n",
    "input_domain = input_domain.clone().detach().requires_grad_(True).to(device)\n",
    "init_val_colloc = init_val_colloc.clone().detach().requires_grad_(True).to(device)\n",
    "dir_boundary_colloc = dir_boundary_colloc.clone().detach().requires_grad_(True).to(device)\n",
    "interior_colloc = interior_colloc.clone().detach().requires_grad_(True).to(device)\n",
    "\n",
    "domain_bounds = torch.tensor([[0.0, -1.0], [0.95, 1.0]], device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11012ff3ec6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the Model\n",
    "\n",
    "# Define the QPINN\n",
    "@qml.qnode(qml.device(\"default.qubit\", wires=N_WIRES), interface=\"torch\")\n",
    "def circuit(x, basis=None):\n",
    "\n",
    "    # Embedding\n",
    "    if EMBEDDING == \"NONE\":\n",
    "        for i in range(N_WIRES):\n",
    "            if i%2 == 0:\n",
    "                qml.RY(x[0], wires=i)\n",
    "            else:\n",
    "                qml.RY(x[1], wires=i)\n",
    "    elif EMBEDDING == \"CHEBYSHEV\":\n",
    "        for i in range(N_WIRES):\n",
    "            if i%2 == 0:\n",
    "                qml.RY(2*torch.arccos(x[0]), wires=i)\n",
    "            else:\n",
    "                qml.RY(2*torch.arccos(x[1]), wires=i)\n",
    "    elif EMBEDDING == \"TOWER_CHEBYSHEV\":\n",
    "        for i in range(N_WIRES):\n",
    "            scaling_factor = 1\n",
    "            if i%2 == 0:\n",
    "                qml.RY(2*scaling_factor*torch.arccos(x[0]), wires=i)\n",
    "            else:\n",
    "                qml.RY(2*scaling_factor*torch.arccos(x[1]), wires=i)\n",
    "                scaling_factor +=1\n",
    "    elif EMBEDDING == \"FNN_BASIS\":\n",
    "        for i in range(N_WIRES):\n",
    "            if i % 2 == 0:\n",
    "                qml.RY(basis[i] * x[0], wires=i)\n",
    "            else:\n",
    "                qml.RY(basis[i] * x[1], wires=i)\n",
    "    \n",
    "    # Variational ansatz\n",
    "    for i in range(N_LAYERS):\n",
    "        for j in range(N_WIRES):\n",
    "            qml.RX(theta[i,j,0], wires=j)\n",
    "            qml.RY(theta[i,j,1], wires=j)\n",
    "            qml.RZ(theta[i,j,2], wires=j)\n",
    "    \n",
    "        for j in range(N_WIRES - 1):\n",
    "            qml.CNOT(wires=[j, j + 1])\n",
    "\n",
    "    # Cost Function\n",
    "    return qml.expval(qml.sum(*[qml.PauliZ(i) for i in range(N_WIRES)]))\n",
    "\n",
    "# Define FNN for the basis\n",
    "class FNNBasisNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_layers, branch_width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.branch_width = branch_width\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(torch.nn.Linear(2, branch_width))\n",
    "        for i in range(n_hidden_layers - 1):\n",
    "            self.layers.append(torch.nn.Linear(branch_width, branch_width))\n",
    "        self.layers.append(torch.nn.Linear(branch_width, N_WIRES))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            x = torch.tanh(self.layers[i](x))\n",
    "        x = self.layers[self.n_hidden_layers](x)\n",
    "        return x\n",
    "\n",
    "def model(x):\n",
    "    # Rescale input to [-0.95, 0.95]       \n",
    "    x_rescaled = 1.9 * (x - domain_bounds[0])/(domain_bounds[1] - domain_bounds[0]) - 0.95\n",
    "    \n",
    "    if EMBEDDING == \"FNN_BASIS\":\n",
    "        return circuit(x_rescaled.T, basisNet(x_rescaled).T)\n",
    "    else:\n",
    "        return circuit(x_rescaled.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d23cc3430c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Reference Solution\n",
    "u_interp = np.load(os.path.dirname(os.path.abspath(\"\"))+ \"/Burgers/burgers_reference_solution.npy\", allow_pickle=True).item()\n",
    "\n",
    "def reference_solution(data):\n",
    "    output = np.zeros(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        output[i] = u_interp([data[i, 0], data[i, 1]]).squeeze()\n",
    "    return output\n",
    "\n",
    "reference_values = torch.tensor(reference_solution(input_domain.detach().cpu()), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce61757b406f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define loss terms\n",
    "\n",
    "def dir_boundary_loss():\n",
    "    u_pred = model(dir_boundary_colloc)\n",
    "    return torch.mean(u_pred**2)\n",
    "\n",
    "\n",
    "def init_val_loss():\n",
    "    u_pred = model(init_val_colloc)\n",
    "    return torch.mean((u_pred - (-torch.sin(torch.pi * init_val_colloc[:, 1]))) ** 2)\n",
    "\n",
    "\n",
    "def pde_res_fnc():\n",
    "    u_pred = model(interior_colloc)\n",
    "\n",
    "    # u_pred = model(input_domain)\n",
    "    # res = torch.mean((u_pred - reference_values) ** 2)\n",
    "    # return res\n",
    "\n",
    "    grad_outputs_1 = torch.ones_like(u_pred)\n",
    "    du = torch.autograd.grad(u_pred, interior_colloc, grad_outputs=grad_outputs_1, create_graph=True)[0]\n",
    "    du_dt_pred = du[:, 0]\n",
    "    du_dx_pred = du[:, 1]\n",
    "\n",
    "    du_du_dx = torch.autograd.grad(du_dx_pred, interior_colloc, grad_outputs=grad_outputs_1, create_graph=True)[0]\n",
    "    du_dx_dx_pred = du_du_dx[:, 1]\n",
    "\n",
    "    res_pde = du_dt_pred + u_pred * du_dx_pred - 0.01 / torch.pi * du_dx_dx_pred\n",
    "\n",
    "    return torch.mean(res_pde**2)\n",
    "\n",
    "\n",
    "def loss_fnc():\n",
    "    loss_dir = dir_boundary_loss()\n",
    "    loss_init = init_val_loss()\n",
    "    loss_pde = pde_res_fnc()\n",
    "    \n",
    "    return BOUNDARY_SCALE * (loss_init + loss_dir) + loss_pde\n",
    "\n",
    "\n",
    "def compute_MSE_ref():\n",
    "    prediction = model(input_domain)\n",
    "    return torch.mean((prediction-reference_values)**2).detach().cpu().item()\n",
    "\n",
    "def compute_lmax_norm():\n",
    "    prediction = model(input_domain)\n",
    "    return torch.max(torch.abs(prediction-reference_values)).detach().cpu().item()\n",
    "\n",
    "def closure():\n",
    "    opt.zero_grad()\n",
    "    l = loss_fnc()\n",
    "    l.backward()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80dfb0497acb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmark different configurations\n",
    "training_iterations = 500\n",
    "\n",
    "EMBEDDING_LIST = [\"FNN_BASIS\", \"TOWER_CHEBYSHEV\"]\n",
    "\n",
    "\n",
    "for EMBEDDING in EMBEDDING_LIST:\n",
    "    theta = torch.rand(N_LAYERS, N_WIRES, 3, device=device, requires_grad=True)\n",
    "        \n",
    "    if EMBEDDING == \"FNN_BASIS\":\n",
    "        basisNet = FNNBasisNet(HIDDEN_LAYERS_FNN, NEURONS_FNN).to(device)\n",
    "        opt = torch.optim.LBFGS([theta, *basisNet.parameters()], line_search_fn=\"strong_wolfe\")\n",
    "    else:\n",
    "        opt = torch.optim.LBFGS([theta], line_search_fn=\"strong_wolfe\")\n",
    "        \n",
    "    loss_history = []\n",
    "    previous_loss = float('inf')\n",
    "    for i in range(training_iterations):\n",
    "        opt.step(closure)\n",
    "        print(f\"Epoch {i}, Loss: {loss_fnc().item():.2E} \\t MSE: {compute_MSE_ref():.2E} \\t\", end=\"\\r\")\n",
    "        loss_history.append(loss_fnc().item())\n",
    "\n",
    "\n",
    "        if abs(previous_loss - loss_fnc().item()) < 1e-10:\n",
    "            break\n",
    "        previous_loss = loss_fnc().item()\n",
    "        \n",
    "    print(f\"Final Loss: {loss_fnc().item():.2E} \\t Embedding: {EMBEDDING} \\t Layers: {N_LAYERS} \\t Qubits: {N_WIRES} \\t Iterations: {i} \\t MSE_ref {compute_MSE_ref():.2E} \\t L_Max_Norm {compute_lmax_norm():.2E}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
