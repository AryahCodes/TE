{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:08:32.022824Z",
     "start_time": "2024-10-21T09:08:28.379122Z"
    }
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.set_num_threads(8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:08:32.039362Z",
     "start_time": "2024-10-21T09:08:32.036936Z"
    }
   },
   "outputs": [],
   "source": [
    "## Constants\n",
    "# FNN Basis Net\n",
    "HIDDEN_LAYERS_FNN = 2\n",
    "NEURONS_FNN = 9\n",
    "\n",
    "# Domain Parameter\n",
    "X_COLLOC_POINTS = 50\n",
    "Y_COLLOC_POINTS = 25\n",
    "BOUNDARY_SCALE = 10e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:08:32.295343Z",
     "start_time": "2024-10-21T09:08:32.125860Z"
    }
   },
   "outputs": [],
   "source": [
    "##  Generate Domain\n",
    "\n",
    "# Generate Collocation Points\n",
    "x = torch.linspace(0.0, 2.0, X_COLLOC_POINTS)\n",
    "y = torch.linspace(0.0, 1.0, Y_COLLOC_POINTS)\n",
    "input_domain = torch.tensor(list(product(x, y)))\n",
    "\n",
    "dir_boundary_mask = (input_domain[:, 0] == 0.0) | (input_domain[:, 0] == 2.0)\n",
    "dir_boundary_colloc = input_domain[dir_boundary_mask]\n",
    "\n",
    "# Neumann Boundary\n",
    "neu_boundary_mask = (input_domain[:, 1] == 0.0) | (input_domain[:, 1] == 1.0)\n",
    "neu_boundary_colloc = input_domain[neu_boundary_mask & ~dir_boundary_mask] \n",
    "\n",
    "# Combined Boundary Mask\n",
    "boundary_mask = dir_boundary_mask | neu_boundary_mask\n",
    "\n",
    "# Filter out boundary points from domain_colloc\n",
    "interior_colloc = input_domain[~boundary_mask]\n",
    "\n",
    "input_domain = input_domain.clone().detach().requires_grad_(True).to(device)\n",
    "dir_boundary_colloc = dir_boundary_colloc.clone().detach().requires_grad_(True).to(device)\n",
    "neu_boundary_colloc = neu_boundary_colloc.clone().detach().requires_grad_(True).to(device)\n",
    "interior_colloc = interior_colloc.clone().detach().requires_grad_(True).to(device)\n",
    "\n",
    "domain_bounds = torch.tensor([[0.0, 0.0], [2.0, 1.0]], device=device)\n",
    "\n",
    "# # Plot domain\n",
    "# plt.scatter(dir_boundary_colloc[:,0].detach().cpu(),dir_boundary_colloc[:,1].detach().cpu(), c=\"r\", label=\"Dirichlet\", s=10)\n",
    "# plt.scatter(neu_boundary_colloc[:,0].detach().cpu(),neu_boundary_colloc[:,1].detach().cpu(), c=\"blue\", label=\"Neumann\", s=10)\n",
    "# plt.scatter(interior_colloc[:,0].detach().cpu(),interior_colloc[:,1].detach().cpu(), c=\"black\", label=\"Interior\", s=10)\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:23:24.398129Z",
     "start_time": "2024-10-21T09:23:24.392364Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create the Model\n",
    "\n",
    "# Define QPINN\n",
    "def circuit(x, basis=None):\n",
    "\n",
    "    # Embedding\n",
    "    if EMBEDDING == \"NONE\":\n",
    "        for i in range(N_WIRES):\n",
    "            if i%2 == 0:\n",
    "                qml.RY(x[0], wires=i)\n",
    "            else:\n",
    "                qml.RY(x[1], wires=i)\n",
    "    elif EMBEDDING == \"CHEBYSHEV\":\n",
    "        for i in range(N_WIRES):\n",
    "            if i%2 == 0:\n",
    "                qml.RY(2*torch.arccos(x[0]), wires=i)\n",
    "            else:\n",
    "                qml.RY(2*torch.arccos(x[1]), wires=i)\n",
    "    elif EMBEDDING == \"TOWER_CHEBYSHEV\":\n",
    "        for i in range(N_WIRES):\n",
    "            scaling_factor = 1\n",
    "            if i%2 == 0:\n",
    "                qml.RY(2*scaling_factor*torch.arccos(x[0]), wires=i)\n",
    "            else:\n",
    "                qml.RY(2*scaling_factor*torch.arccos(x[1]), wires=i)\n",
    "                scaling_factor +=1\n",
    "    elif EMBEDDING == \"FNN_BASIS\":\n",
    "        for i in range(N_WIRES):\n",
    "            if i % 2 == 0:\n",
    "                qml.RY(basis[i] * x[0], wires=i)\n",
    "            else:\n",
    "                qml.RY(basis[i] * x[1], wires=i)\n",
    "    \n",
    "    # Variational ansatz\n",
    "    for i in range(N_LAYERS):\n",
    "        for j in range(N_WIRES):\n",
    "            qml.RX(theta[i,j,0], wires=j)\n",
    "            qml.RY(theta[i,j,1], wires=j)\n",
    "            qml.RZ(theta[i,j,2], wires=j)\n",
    "    \n",
    "        for j in range(N_WIRES - 1):\n",
    "            qml.CNOT(wires=[j, j + 1])\n",
    " \n",
    "    # Cost Function\n",
    "    return qml.expval(qml.sum(*[qml.PauliZ(i) for i in range(N_WIRES)]))\n",
    "\n",
    "# Define FNN for the basis\n",
    "class FNNBasisNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_layers, branch_width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.branch_width = branch_width\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(torch.nn.Linear(2, branch_width))\n",
    "        for i in range(n_hidden_layers - 1):\n",
    "            self.layers.append(torch.nn.Linear(branch_width, branch_width))\n",
    "        self.layers.append(torch.nn.Linear(branch_width, N_WIRES))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            x = torch.tanh(self.layers[i](x))\n",
    "        x = self.layers[self.n_hidden_layers](x)\n",
    "        return x\n",
    "\n",
    "def model(x):\n",
    "    # Rescale input to [-0.95, 0.95]\n",
    "    x_rescaled = 1.9 * (x - domain_bounds[0])/(domain_bounds[1] - domain_bounds[0]) - 0.95\n",
    "    \n",
    "    if EMBEDDING == \"FNN_BASIS\":\n",
    "        return circuit_qnode(x_rescaled.T, basisNet(x_rescaled).T)\n",
    "    else:\n",
    "        return circuit_qnode(x_rescaled.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:23:25.394921Z",
     "start_time": "2024-10-21T09:23:25.317586Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load the reference solution\n",
    "u_interp = np.load(\n",
    "    os.path.dirname(os.path.abspath(\"\")) + \"/Poisson/poisson_reference_solution.npy\",\n",
    "    allow_pickle=True,\n",
    ").item()\n",
    "\n",
    "def reference_solution(data):\n",
    "    output = np.zeros(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        output[i] = u_interp([data[i, 0], data[i, 1]]).squeeze()\n",
    "    return output\n",
    "\n",
    "reference_values = torch.tensor(reference_solution(input_domain.detach().cpu()), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:23:26.287284Z",
     "start_time": "2024-10-21T09:23:26.281529Z"
    }
   },
   "outputs": [],
   "source": [
    "## Define the problem\n",
    "def source_term(x):\n",
    "    return 10 * torch.exp(-((x[:, 0] - 0.5) ** 2 + (x[:, 1] - 0.5) ** 2) / 0.02)\n",
    "\n",
    "def neu_boundary_term(x):\n",
    "    return torch.sin(5 * x[:, 0])\n",
    "\n",
    "def dir_loss_fnc():\n",
    "    u_dir = model(dir_boundary_colloc)\n",
    "    return torch.mean(u_dir**2)\n",
    "\n",
    "def neu_loss_fnc():\n",
    "    u_neu = model(neu_boundary_colloc)\n",
    "\n",
    "    du_d = torch.autograd.grad(u_neu, neu_boundary_colloc, grad_outputs=torch.ones_like(u_neu), create_graph=True)[0]\n",
    "    du_dy = du_d[:, 1]\n",
    "\n",
    "    # Flip signs for first values, since they have to be outward facing relative to the domain\n",
    "    du_dy[::2] *= -1.0\n",
    "\n",
    "    g = neu_boundary_term(neu_boundary_colloc)\n",
    "    return torch.mean((du_dy - g) ** 2)\n",
    "\n",
    "def pde_loss_fnc():\n",
    "    u = model(interior_colloc)\n",
    "    f = source_term(interior_colloc)\n",
    "\n",
    "    grad_out = torch.ones_like(u)\n",
    "    du_d = torch.autograd.grad(u, interior_colloc, grad_outputs=grad_out, create_graph=True)[0]\n",
    "    du_dx = du_d[:, 0]\n",
    "    du_dy = du_d[:, 1]\n",
    "\n",
    "    du_dxd = torch.autograd.grad(du_dx, interior_colloc, grad_outputs=grad_out, create_graph=True)[0]\n",
    "    du_dxdx = du_dxd[:, 0]\n",
    "\n",
    "    du_dyd = torch.autograd.grad(du_dy, interior_colloc, grad_outputs=grad_out, create_graph=True)[0]\n",
    "    du_dydy = du_dyd[:, 1]\n",
    "\n",
    "    pde_res = -du_dxdx - du_dydy - f\n",
    "    return torch.mean(pde_res**2)\n",
    "\n",
    "\n",
    "def loss_fnc():\n",
    "    dir_loss = dir_loss_fnc()\n",
    "    neu_loss = neu_loss_fnc()\n",
    "    pde_loss = pde_loss_fnc()\n",
    "\n",
    "    return BOUNDARY_SCALE * (dir_loss + neu_loss) + pde_loss\n",
    "\n",
    "def compute_MSE_ref():\n",
    "    prediction = model(input_domain)\n",
    "    return torch.mean((prediction-reference_values)**2).detach().cpu().item()\n",
    "\n",
    "def compute_lmax_norm():\n",
    "    prediction = model(input_domain)\n",
    "    return torch.max(torch.abs(prediction-reference_values)).detach().cpu().item()\n",
    "\n",
    "def closure():\n",
    "    opt.zero_grad()\n",
    "    l = loss_fnc()\n",
    "    l.backward()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:23:49.271191Z",
     "start_time": "2024-10-21T09:23:26.963784Z"
    }
   },
   "outputs": [],
   "source": [
    "## Benchmark different configurations\n",
    "\n",
    "EMBEDDING_LIST = [\"TOWER_CHEBYSHEV\"]\n",
    "\n",
    "data = np.zeros((5,4,2)) # layer, qubits, (loss, MSE_re)\n",
    "\n",
    "for EMBEDDING in EMBEDDING_LIST:\n",
    "    for k,N_LAYERS in enumerate([5]):\n",
    "        for l,N_WIRES in enumerate([2,4]):\n",
    "            print(f\"Embedding: {EMBEDDING} \\t Layers: {N_LAYERS} \\t Qubits: {N_WIRES}\")\n",
    "            \n",
    "            circuit_qnode = qml.QNode(circuit, device=qml.device(\"default.qubit\", wires=N_WIRES), max_diff=2)\n",
    "            theta = torch.rand(N_LAYERS, N_WIRES, 3, device=device, requires_grad=True)\n",
    "\n",
    "            if EMBEDDING == \"FNN_BASIS\":\n",
    "                basisNet = FNNBasisNet(HIDDEN_LAYERS_FNN, NEURONS_FNN).to(device)\n",
    "                opt = torch.optim.LBFGS([theta, *basisNet.parameters()], line_search_fn=\"strong_wolfe\")\n",
    "            else:\n",
    "                opt = torch.optim.LBFGS([theta], line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "\n",
    "            previous_loss = float('inf')\n",
    "            for i in range(100):\n",
    "                opt.step(closure)\n",
    "                print(f\"Epoch {i}, Loss: {loss_fnc().item():.2E}\", end=\"\\r\")\n",
    "\n",
    "                if previous_loss == loss_fnc().item():\n",
    "                    break\n",
    "                previous_loss = loss_fnc().item()\n",
    "                \n",
    "            data[k,l,0] = loss_fnc().item()\n",
    "            data[k,l,1] = compute_MSE_ref()         \n",
    "\n",
    "                \n",
    "            print(f\"Final Loss: {loss_fnc().item():.2E} \\t Iteration: {i} \\t Embedding: {EMBEDDING} \\t Layers: {N_LAYERS} \\t Qubits: {N_WIRES} \\t Iterations: {i} \\t L2_Norm {compute_MSE_ref():.2E} \\t L_Max_Norm {compute_lmax_norm():.2E}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
